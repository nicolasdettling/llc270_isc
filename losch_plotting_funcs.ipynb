{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ab6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sq(a):\n",
    "    import numpy as np\n",
    "    a = np.squeeze(a)\n",
    "    masked_array=np.ma.masked_where(a==0., a)\n",
    "    return masked_array\n",
    "\n",
    "def mosaic_llc(field):\n",
    "    return np.vstack([np.hstack([np.vstack([np.rot90(field[i]) for i in [9,8,7]]),\n",
    "                                 np.vstack([np.rot90(field[i]) for i in [12,11,10]]),\n",
    "                                 np.vstack([field[i] for i in [0,1,2]]),\n",
    "                                 np.vstack([field[i] for i in [3,4,5]])]),\n",
    "                      np.hstack([np.rot90(field[6])*np.tri(90)[::-1,:],np.triu(np.rot90(field[6],k=2))*np.tri(90)[::-1,:],\n",
    "                                 np.triu(np.rot90(field[6],k=-1)),np.zeros(field[6].shape)])])[30:315,:]\n",
    "\n",
    "def llc13to5faces(field):\n",
    "    \"\"\"\n",
    "    fld = llc13to5faces(field) returns a list of 5 faces constructed from \n",
    "    the input of a 13-faces field as returned from \n",
    "    xmitgcm.open_mdsdataset(...,geometry='llc')\n",
    "    \"\"\"\n",
    "    return [np.vstack((field[0,...],field[1,...],field[2,...])),\n",
    "            np.vstack((field[3,...],field[4,...],field[5,...])),\n",
    "            field[6,...],\n",
    "            np.hstack((field[7,...],field[8,...],field[9,...])),\n",
    "            np.hstack((field[10,...],field[11,...],field[12,...]))]\n",
    "\n",
    "def symNorm(vmax):\n",
    "    import matplotlib.colors as mcolors\n",
    "    return mcolors.Normalize(vmin=-vmax,vmax=vmax)\n",
    "\n",
    "face_connections = {'face':\n",
    "                    {0: {'X':  ((12, 'Y', False), (3, 'X', False)),\n",
    "                         'Y':  (None,             (1, 'Y', False))},\n",
    "                     1: {'X':  ((11, 'Y', False), (4, 'X', False)),\n",
    "                         'Y':  ((0, 'Y', False),  (2, 'Y', False))},\n",
    "                     2: {'X':  ((10, 'Y', False), (5, 'X', False)),\n",
    "                         'Y':  ((1, 'Y', False),  (6, 'X', False))},\n",
    "                     3: {'X':  ((0, 'X', False),  (9, 'Y', False)),\n",
    "                         'Y':  (None,             (4, 'Y', False))},\n",
    "                     4: {'X':  ((1, 'X', False),  (8, 'Y', False)),\n",
    "                         'Y':  ((3, 'Y', False),  (5, 'Y', False))},\n",
    "                     5: {'X':  ((2, 'X', False),  (7, 'Y', False)),\n",
    "                         'Y':  ((4, 'Y', False),  (6, 'Y', False))},\n",
    "                     6: {'X':  ((2, 'Y', False),  (7, 'X', False)),\n",
    "                         'Y':  ((5, 'Y', False),  (10, 'X', False))},\n",
    "                     7: {'X':  ((6, 'X', False),  (8, 'X', False)),\n",
    "                         'Y':  ((5, 'X', False),  (10, 'Y', False))},\n",
    "                     8: {'X':  ((7, 'X', False),  (9, 'X', False)),\n",
    "                         'Y':  ((4, 'X', False),  (11, 'Y', False))},\n",
    "                     9: {'X':  ((8, 'X', False),  None),\n",
    "                         'Y':  ((3, 'X', False),  (12, 'Y', False))},\n",
    "                     10: {'X': ((6, 'Y', False),  (11, 'X', False)),\n",
    "                          'Y': ((7, 'Y', False),  (2, 'X', False))},\n",
    "                     11: {'X': ((10, 'X', False), (12, 'X', False)),\n",
    "                          'Y': ((8, 'Y', False),  (1, 'X', False))},\n",
    "                     12: {'X': ((11, 'X', False), None),\n",
    "                          'Y': ((9, 'Y', False),  (0, 'X', False))}}}\n",
    "\n",
    "def plot2dmap(ax,fld,levs,tstr='dummy',cmap=None):\n",
    "    \n",
    "    ax.set_global()\n",
    "    # for iface in [0,1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "    # for iface in [0,1,2,3,4,5,10,11,12]:\n",
    "    for iface in range(13):\n",
    "        if iface==12: \n",
    "            clrbr=True\n",
    "            # cbarargs={\"orientation\": \"horizontal\"}\n",
    "            cbarargs={\"extend\": \"both\", \"orientation\": \"horizontal\"}\n",
    "            if levs.vmin==0.: \n",
    "                cbarargs[\"extend\"] = \"max\"\n",
    "        else:\n",
    "            clrbr=False\n",
    "            cbarargs=None\n",
    "\n",
    "        fld.isel(face=iface).plot.pcolormesh(ax=ax, transform=cart.crs.PlateCarree(), x=\"XC\", y=\"YC\", norm=levs,\n",
    "                                             add_colorbar=clrbr, cmap=cmap, cbar_kwargs=cbarargs)\n",
    "    \n",
    "    ax.set_title('%s'%(tstr))\n",
    "    ax.coastlines()\n",
    "    ax.add_feature(cart.feature.LAND, zorder=100, edgecolor='k')\n",
    "    ax.gridlines()\n",
    "    \n",
    "def mdsTo13faces(field):\n",
    "    \"\"\"fld = llcTo13faces(field) returns an array where axis=-2 has been\n",
    "    split into 13 to for 13 llc-faces\n",
    "\n",
    "    \"\"\"\n",
    "    nn,nx = field.shape[-2:]\n",
    "    if nn/nx == 13:\n",
    "        n = nn//nx//4\n",
    "        dims = field.shape\n",
    "        fld13 = field.reshape( ( *dims[:-2], 13, nx, nx ) )\n",
    "        # move last 3 dimensions to the front for easier manipulation\n",
    "        fld13 = np.moveaxis(np.moveaxis(\n",
    "            np.moveaxis(fld13, -1, 0), -1, 0), -1, 0)\n",
    "        tmp = np.zeros( (6, nx, nx, *dims[:-2]) )\n",
    "        # re-arrange\n",
    "        for k in range(n):\n",
    "            tt = fld13[7:,k::n,:,...].reshape(2*nx,nx,*dims[:-2])\n",
    "            tmp[  k,...] = tt[:nx,...]\n",
    "            tmp[3+k,...] = tt[nx:,...]\n",
    "\n",
    "        fld13[7:,...] = tmp\n",
    "        # move dimensions back\n",
    "        fld13 = np.moveaxis(np.moveaxis(\n",
    "            np.moveaxis(fld13,0,-1),0,-1),0,-1)\n",
    "    else:\n",
    "        fld13=np.NaN\n",
    "        raise ValueError(\n",
    "            \"%s %i,%i with %i/%i = %.1f but not = 13\"%(\n",
    "                \"unexpected horizontal llc-dimensions\",nn,nx,nn,nx,nn/nx))\n",
    "\n",
    "    return fld13\n",
    "\n",
    "def flat2d(x):\n",
    "    if type(x) is np.ndarray:\n",
    "        x0 = np.concatenate( [np.concatenate([x[:,0,:,:],x[:,1,:,:],x[:,2,:,:]], axis=-2),\n",
    "                              np.concatenate([x[:,3,:,:],x[:,4,:,:],x[:,5,:,:]], axis=-2)], axis=-1 )\n",
    "        y0 = np.concatenate( [np.concatenate([x[:,7,:,:],x[:,8,:,:],x[:,9,:,:]], axis=-1),\n",
    "                              np.concatenate([x[:,10,:,:],x[:,11,:,:],x[:,12,:,:]], axis=-1)], axis=-2 )\n",
    "    else:\n",
    "        x0 = xr.concat( [xr.concat( [x.isel(face=0),x.isel(face=1),x.isel(face=2)], dim = 'j' ),\n",
    "                         xr.concat( [x.isel(face=3),x.isel(face=4),x.isel(face=5)], dim = 'j' )], dim='i' )\n",
    "        y0 = xr.concat( [xr.concat( [x.isel(face=7),x.isel(face=8),x.isel(face=9)], dim = 'i' ),\n",
    "                         xr.concat( [x.isel(face=10),x.isel(face=11),x.isel(face=12)], dim = 'i' )], dim='j' )\n",
    "    return np.concatenate((x0,np.rot90(y0,k=1,axes=(-2,-1))), axis=-1)\n",
    "\n",
    "def calc_drake_passage_transport(ds):\n",
    "    vtrans = (ds.VVELMASS*ds.drF).sum('k')*ds.dxG * 1e-6\n",
    "    return (vtrans.sel(face=11,i=range(87,90),j_g=62).sum('i') + vtrans.sel(face=12,i=range(20),j_g=62).sum('i'))\n",
    "\n",
    "def make_masks(coords, withoutArctic=True):\n",
    "    global_mask = coords.hFacC.isel(k=0)\n",
    "    # global_mask[6,:,:]=0. # delete Arctic face\n",
    "    global_mask[2,80:,60:]=0.\n",
    "    global_mask[7,:,:13]=0.\n",
    "    global_mask[10,:43,:11]=0.\n",
    "    # remove Hudson\n",
    "    global_mask[10,30:54,5:39] = 0.\n",
    "    global_mask[10,30:62,10:39] = 0.\n",
    "    #\n",
    "    atlantic_mask = global_mask.where(coords.YC>-35).where( # Southern Ocean\n",
    "        np.logical_and(coords.XC<20,coords.XC>-98)).where( # most of the non-Atlantic Ocean\n",
    "        np.logical_or(coords.XC<0,np.logical_or(coords.YC<30,coords.YC>47))).where(\n",
    "        np.logical_or(coords.XC<-9,np.logical_or(coords.YC<34,coords.YC>38))).where( # Strait of Gibraltar\n",
    "        np.logical_or(coords.XC>-70,coords.YC>9)).where( # East Pacific\n",
    "        np.logical_or(coords.XC>-84,coords.YC>14)).where( # Isthmus of Panama etc.\n",
    "        np.logical_or(coords.XC>-90,coords.YC>18)).where(\n",
    "        np.logical_or(coords.XC>-70,coords.YC<50)).fillna(0)\n",
    "    indopacific_mask = (global_mask-atlantic_mask).where(\n",
    "        np.logical_and(coords.YC>-35,coords.YC<70)).fillna(0)\n",
    "    # remove Hudson\n",
    "    indopacific_mask[10,10:,:39] = 0.\n",
    "    # remove Med and parts of Arctic\n",
    "    indopacific_mask[ 2,20:,29:84] = 0.\n",
    "    # remove Bering strait and Chukchy Sea\n",
    "    indopacific_mask[ 7,:,:14] = 0.\n",
    "    if withoutArctic:\n",
    "        global_mask[6,:,:]=0. # delete Arctic face\n",
    "        atlantic_mask[6,:,:]=0. # delete Arctic face\n",
    "        indopacific_mask[6,:,:]=0. # delete Arctic face\n",
    "    return global_mask.values, atlantic_mask.values, indopacific_mask.values\n",
    "\n",
    "def zonal_mean(ds,fld,msk):\n",
    "    # mask the Med\n",
    "    dvol = flat2d(ds.hFacC*ds.rA*ds.drF*msk)\n",
    "    # mask the Med\n",
    "    dvol[:,200:217,33:80]=0\n",
    "    dvol[:,217:222,40:60]=0\n",
    "    ra = dvol.sum(axis=-1)\n",
    "    ra[ra==0]=np.Inf\n",
    "    fldz = (flat2d(fld)*dvol).sum(axis=-1)/ra\n",
    "    return np.ma.masked_array(fldz,fldz==0)\n",
    "\n",
    "def zonal_sum(fld):\n",
    "    # zonal integral of scalar field\n",
    "    return flat2d(fld).sum(axis=-1)\n",
    "\n",
    "def zonal_lat_bin(clat,res=1.):\n",
    "    lat_group = np.round(clat/res)*res\n",
    "    latg = np.unique(lat_group.values.ravel())\n",
    "    return latg - 0.5*res\n",
    "    \n",
    "def zonal_sum_bin(data,clat,res=1.):\n",
    "    lat_group = np.round(clat/res)*res\n",
    "    return data.where(data>0.).groupby(lat_group).sum()\n",
    "    \n",
    "def calc_flux_divergence(dl):\n",
    "    # this is done separately\n",
    "    # grd = xgcm.Grid(dl, periodic=False, face_connections=face_connections)\n",
    "    # layer flux in two directions\n",
    "    flxx = dl.LaUH1RHO*dl.dyG\n",
    "    flxy = dl.LaVH1RHO*dl.dxG\n",
    "    # difference in the x and y directions\n",
    "    diff_flx = grd.diff_2d_vector({'X': flxx, 'Y': flxy}, boundary='fill')\n",
    "    # divergence\n",
    "    return diff_flx['X'] + diff_flx['Y']\n",
    "\n",
    "def calc_wflux_dia(dl):\n",
    "    flx_div = calc_flux_divergence(dl)\n",
    "    # determine vertical coordinate\n",
    "    try: z = dl.Zl.values\n",
    "    except:\n",
    "        try: z = dl.Z.values\n",
    "        except: \n",
    "            print('no z-coordintate')\n",
    "\n",
    "    if z[0]>0: # p-coords\n",
    "        # compute wflux at w-points (below c-points),\n",
    "        # integrating (from the bottom up) cumulatively,\n",
    "        wflx = flx_div.cumsum(dim='l1_c')\n",
    "        wflx[-1,:] = 0.\n",
    "    else:\n",
    "        # compute wflux at w-points (above c-points) by reversing the k-axis,\n",
    "        # integrating (now from the bottom up) cumulatively,\n",
    "        # assuming wflx=0 at n+1\n",
    "        wflux = -flx_div.reindex(l1_c=flx_div.l1_c[::-1]).cumsum(dim='l1_c')\n",
    "        # and reverse the k-axis again\n",
    "        wflx = wflux.reindex(l1_c=wflux.l1_c[::-1])\n",
    "    return wflx\n",
    "\n",
    "def calc_std_xr(fld2,fld):\n",
    "    # xarray version\n",
    "    var = fld2 - fld**2\n",
    "    return np.sqrt(var.where(var>0.,0.))\n",
    "\n",
    "def calc_std_np(fld2,fld):\n",
    "    # numpy version\n",
    "    var = fld2-fld**2\n",
    "    return np.where(var<0.,0,np.sqrt(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9345c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_line_value(f):\n",
    "    return float(next(f).strip().split()[-1].replace('E','e'))\n",
    "\n",
    "def get_parms (fname):\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            if '/* Monitor output interval ( s ). */' in line:\n",
    "                mondt = get_next_line_value(f)\n",
    "                # ll = next(f).strip().split()\n",
    "                # mondt = float(ll[-1].replace('E','e'))\n",
    "            elif 'mass2rUnit' in line:\n",
    "                m2rUnit = get_next_line_value(f)\n",
    "            elif '/* Reference density (Boussinesq)  ( kg/m^3 ) */' in line:\n",
    "                rhoConst = get_next_line_value(f)\n",
    "            elif '/* density of sea ice (kg/m3) */' in line:\n",
    "                rhoIce = get_next_line_value(f)\n",
    "            elif 'startDate_1' in line:\n",
    "                startDate = line.split('=')[-1]\n",
    "            elif '/* Gravitational acceleration ( m/s^2 ) */' in line:\n",
    "                gravity = get_next_line_value(f)\n",
    "            elif 'gravity orientation relative to vertical coordinate' in line:\n",
    "                gravitySign = get_next_line_value(f)\n",
    "\n",
    "    return mondt, m2rUnit, rhoConst, rhoIce, gravity*gravitySign, startDate\n",
    "\n",
    "def get_output (fnames, mystring):\n",
    "    \"\"\"parse fname and get some numbers out\"\"\"\n",
    "    timev = []\n",
    "    myvar = []\n",
    "    if mystring[:3]=='exf':\n",
    "        timename = 'exf_time_sec'\n",
    "    elif mystring[:3]=='sea':\n",
    "        timename = 'seaice_time_sec'\n",
    "    else:\n",
    "        timename = 'time_secondsf'\n",
    "    for fname in fnames:\n",
    "        try:\n",
    "            f = open(fname)\n",
    "        except:\n",
    "            print(fname + \" does not exist, continuing\")\n",
    "        else:\n",
    "            for line in f:\n",
    "                if timename in line:\n",
    "                    ll = line.split()\n",
    "                    timev.append(float(ll[-1].replace('D','e')))\n",
    "                elif mystring in line:\n",
    "                    ll = line.split()\n",
    "                    myvar.append(float(ll[-1].replace('D','e')))\n",
    "\n",
    "            f.close()\n",
    "\n",
    "    # reverse order\n",
    "    timevs=np.asarray(timev[::-1])\n",
    "    myvars=np.asarray(myvar[::-1])\n",
    "    # timevs=np.asarray(timev)\n",
    "    # myvars=np.asarray(myvar)\n",
    "    # This sorts again in ascending order and returns the index of\n",
    "    # the first occurrence of duplicates. Because we have reverted the order\n",
    "    # before, in this way we use the values at the beginning of a pickup run\n",
    "    # rather than the overlapping values of the previous (potentially crashed)\n",
    "    # run\n",
    "    timevs, isort = np.unique(timevs,return_index=True)\n",
    "    myvars=myvars[isort]\n",
    "\n",
    "    return timevs, myvars\n",
    "# done\n",
    "\n",
    "def correct_jumps(x):\n",
    "    return x\n",
    "#     ii = np.where(np.abs(np.diff(x)) > 0.1*x.std())[0]\n",
    "#     y = np.copy(x)\n",
    "#     for i in ii:\n",
    "# #        print(i,y[i],y[i+1],2*y[i+1]-y[i])\n",
    "#         y[i+1:] = y[i+1:]-y[i+1]+y[i]\n",
    "\n",
    "#     return y\n",
    "\n",
    "def readstats(fname):\n",
    "    '''\n",
    "    locals,totals,itrs = readstats(fname)\n",
    "\n",
    "    Read a diagstats text file into record arrays (or dictionaries).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : string\n",
    "        name of diagstats file to read\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    locals : record array or dict of arrays\n",
    "        local statistics, shape (len(itrs), Nr, 5)\n",
    "    totals : record array or dict of arrays\n",
    "        column integrals, shape (len(itrs), 5)\n",
    "    itrs : list of int\n",
    "        iteration numbers found in the file\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The 5 columns of the resulting arrays are average, std.dev, min, max and total volume.\n",
    "    - There is a record (or dictionary key) for each field found in the file.\n",
    "\n",
    "    '''\n",
    "    nstats = 5\n",
    "    flds = []\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            if line.startswith('# end of header'):\n",
    "                break\n",
    "\n",
    "            m = re.match(r'^# ([^:]*) *: *(.*)$', line.rstrip())\n",
    "            if m:\n",
    "                var,val = m.groups()\n",
    "                if var.startswith('Fields'):\n",
    "                    flds = val.split()\n",
    "                if var.startswith('Regions'):\n",
    "                    regs = val.split()\n",
    "\n",
    "        if len(regs) > 1:\n",
    "            res = dict((fld,dict((reg,[]) for reg in regs)) for fld in flds)\n",
    "        else:\n",
    "            res = dict((fld,[]) for fld in flds)\n",
    "        itrs = dict((fld,[]) for fld in flds)\n",
    "\n",
    "        line = f.readline()\n",
    "        while not line.startswith('# records'):\n",
    "\n",
    "            m = re.match(r' field : *([^ ]*) *; Iter = *([0-9]*) *; region # *([0-9]*) ; nb\\.Lev = *([0-9]*)', line)\n",
    "            if m:\n",
    "                fld,itr,reg,nlev = m.groups()\n",
    "                itrs[fld].append(int(itr))\n",
    "                nlevs = int(nlev)\n",
    "                if nlevs > 1: nlevs=nlevs+1\n",
    "                tmp = np.zeros((nlevs,nstats))\n",
    "                line = f.readline()\n",
    "                while not (line.strip() == '' or line.startswith(' field')):\n",
    "                    if not line.startswith(' k'):\n",
    "                        cols = line.strip().split()\n",
    "                        k = int(cols[0])\n",
    "                        tmp[k] = [float(s) for s in cols[1:]]\n",
    "\n",
    "                    line = f.readline()\n",
    "\n",
    "                if len(regs) > 1: res[fld][reg].append(tmp)\n",
    "                else: res[fld].append(tmp)\n",
    "\n",
    "            # else:\n",
    "            #     raise ValueError('readstats: parse error: ' + line)\n",
    "\n",
    "            else:\n",
    "                line = f.readline()\n",
    "\n",
    "    if len(regs)>1:\n",
    "        totals = dict((fld,np.squeeze(np.array(res[fld]['0']))) for fld in flds)\n",
    "        locals = dict((fld,[]) for fld in flds)\n",
    "        for fld in flds:\n",
    "            for reg in regs:\n",
    "                if reg!='0':\n",
    "                    locals[fld].append(np.squeeze(np.array(res[fld][reg])))\n",
    "\n",
    "        locals = dict((fld,np.array(locals[fld])) for fld in flds)\n",
    "        return locals, totals, itrs\n",
    "    else:\n",
    "        try:\n",
    "            all = np.rec.fromarrays(\n",
    "                [np.array(res[fld]) for fld in flds], names=flds)\n",
    "            return all[:,1:,...],all[:,0,...],itrs\n",
    "        except:\n",
    "            totals = dict((fld,np.array(res[fld])[:,0,...]) for fld in flds)\n",
    "            locals = dict((fld,np.array(res[fld])[:,1:,]) for fld in flds)\n",
    "            return locals,totals,itrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def compute_moc_layers(dl,msk):\n",
    "    wflux = calc_wflux_dia(dl)\n",
    "    return compute_moc(wflux*msk)\n",
    "\n",
    "def compute_moc(wflux):\n",
    "    # zonal integral\n",
    "    wflx = zonal_sum(wflux)\n",
    "    # order of integration: from north to south because of Atlantic MOC, requires sign change\n",
    "    mocstrf = -np.flip(np.flip(wflx,axis=-1).cumsum(axis=-1),axis=-1)\n",
    "    mocstrf[wflx==0]=0.\n",
    "    return mocstrf\n",
    "\n",
    "def compute_layers(dl,msk):\n",
    "    # determine vertical coordinate\n",
    "    try: z = dl.Zl.values\n",
    "    except:\n",
    "        try: z = dl.Z.values\n",
    "        except: \n",
    "            print('no z-coordintate')\n",
    "\n",
    "    pCoords = False\n",
    "    if z[0]>0: pCoords=True\n",
    "    \n",
    "    grd = xgcm.Grid(dl, periodic=False, face_connections=face_connections)\n",
    "    lahc = grd.interp_2d_vector({'X': dl.LaHw1RHO, \n",
    "                                 'Y': dl.LaHs1RHO},\n",
    "                                 to = 'center', boundary='fill')\n",
    "    lath = 0.5*(lahc['X']+lahc['Y'])*msk\n",
    "    # not sure if this is better or worse, but does not make much of a difference\n",
    "    #lath = np.maximum(lahc['X'],lahc['Y'])*msk\n",
    "    zzz = flat2d(lath)\n",
    "    # first do the zonal average\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        zz = zzz.mean(axis=-1,where=zzz!=0)\n",
    "        #zz = zzz.where(zzz!=0).mean(axis=-1)\n",
    "    zz[np.isnan(zz)]=0 # need to get rid of NaNs etc.\n",
    "    # then do the vertical integral\n",
    "    z = zz.cumsum(axis=0)\n",
    "    #z[zz==0]=0 # this does not work\n",
    "    # The top level coordinate should always be zero (surface),\n",
    "    # but with the cumulative sum, the first value of z is the \n",
    "    # depth of the first interface; here push down all values to k+1\n",
    "    z = np.roll(z,1,axis=0)\n",
    "    # and make sure that the surface layer is zero\n",
    "    z[0,:]=0\n",
    "    # if pCoords: \n",
    "    #     z = np.roll(z,1,axis=0)\n",
    "    #     z[0,:]=0\n",
    "    # else:\n",
    "      \n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff5020a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyresample\n",
    "\n",
    "class LLCMapper:\n",
    "\n",
    "    def __init__(self, ds, dx=0.25, dy=0.25):\n",
    "        # Extract LLC 2D coordinates\n",
    "        lons_1d = ds.XC.values.ravel()\n",
    "        lats_1d = ds.YC.values.ravel()\n",
    "\n",
    "        # Define original grid\n",
    "        self.orig_grid = pyresample.geometry.SwathDefinition(lons=lons_1d, lats=lats_1d)\n",
    "\n",
    "        # Longitudes latitudes to which we will we interpolate\n",
    "        lon_tmp = np.arange(-180, 180, dx) + dx/2\n",
    "        lat_tmp = np.arange(-90, 90, dy) + dy/2\n",
    "\n",
    "        # Define the lat lon points of the two parts.\n",
    "        self.new_grid_lon, self.new_grid_lat = np.meshgrid(lon_tmp, lat_tmp)\n",
    "        self.new_grid  = pyresample.geometry.GridDefinition(lons=self.new_grid_lon,\n",
    "                                                            lats=self.new_grid_lat)\n",
    "\n",
    "    def __call__(self, da, ax=None, lon_0=-60, tstr=None, **plt_kwargs):\n",
    "\n",
    "        assert set(da.dims) == set(['face', 'j', 'i']), \"da must have dimensions ['face', 'j', 'i']\"\n",
    "\n",
    "        field = pyresample.kd_tree.resample_nearest(self.orig_grid, da.values,\n",
    "                                                    self.new_grid,\n",
    "                                                    radius_of_influence=100000,\n",
    "                                                    fill_value=None)\n",
    "\n",
    "        x,y = self.new_grid_lon, self.new_grid_lat\n",
    "\n",
    "        p = ax.pcolormesh(x, y, field, transform=cart.crs.PlateCarree(), **plt_kwargs)\n",
    "        #p = ax.contourf(x, y, field, transform=cart.crs.PlateCarree(), **plt_kwargs)\n",
    "\n",
    "        ax.coastlines()\n",
    "        # ax.add_feature(cart.feature.LAND, zorder=100, edgecolor='k')\n",
    "        ax.add_feature(cart.feature.LAND, facecolor=landcolor, edgecolor='k',  zorder=3, linewidth=0.3)\n",
    "        gl = ax.gridlines(zorder=4)\n",
    "\n",
    "        if tstr is not None:\n",
    "            ax.set_title('%s'%(tstr))\n",
    "            \n",
    "        label = None\n",
    "        # if da.name is not None:\n",
    "        #     label = da.name\n",
    "        # if 'units' in da.attrs:\n",
    "        #     label += ' (%s)' % da.attrs['units']\n",
    "        # cbarextend='both'\n",
    "        # try:\n",
    "        #     mynorm = plt_kwargs.pop('norm')\n",
    "        #     if mynorm.vmin == 0.: cbarextend='max'\n",
    "        # except:\n",
    "        #     cbarextend='both'\n",
    "\n",
    "        # shrinkfac=1.\n",
    "        # cb = plt.colorbar(p, ax=ax, shrink=shrinkfac, label=label, extend=cbarextend, orientation='horizontal')\n",
    "\n",
    "        return ax, p, gl\n",
    "    \n",
    "class LLCinterp:\n",
    "\n",
    "    def __init__(self, ds, dx=0.25, dy=0.25):\n",
    "        # Extract LLC 2D coordinates\n",
    "        lons_1d = ds.XC.values.ravel()\n",
    "        lats_1d = ds.YC.values.ravel()\n",
    "\n",
    "        # Define original grid\n",
    "        self.orig_grid = pyresample.geometry.SwathDefinition(\n",
    "            lons=lons_1d, lats=lats_1d)\n",
    "\n",
    "        # Longitudes latitudes to which we will we interpolate\n",
    "        lon_tmp = np.arange(-180, 180, dx) + dx/2\n",
    "        lat_tmp = np.arange(-90, 90, dy) + dy/2\n",
    "\n",
    "        # Define the lat lon points of the two parts.\n",
    "        self.new_grid_lon, self.new_grid_lat = np.meshgrid(lon_tmp, lat_tmp)\n",
    "        self.new_grid  = pyresample.geometry.GridDefinition(\n",
    "            lons=self.new_grid_lon, lats=self.new_grid_lat)\n",
    "\n",
    "    def __call__(self, da):\n",
    "\n",
    "        assert set(da.dims) == set(\n",
    "            ['face', 'j', 'i']), \"da must have dimensions ['face', 'j', 'i']\"\n",
    "\n",
    "        field = pyresample.kd_tree.resample_nearest(self.orig_grid, da.values,\n",
    "                                                    self.new_grid,\n",
    "                                                    radius_of_influence=100e3,\n",
    "                                                    fill_value=None)\n",
    "        return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2518c828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyresample\n",
    "\n",
    "class LLCMapper_noland:\n",
    "\n",
    "    def __init__(self, ds, dx=0.25, dy=0.25):\n",
    "        # Extract LLC 2D coordinates\n",
    "        lons_1d = ds.XC.values.ravel()\n",
    "        lats_1d = ds.YC.values.ravel()\n",
    "\n",
    "        # Define original grid\n",
    "        self.orig_grid = pyresample.geometry.SwathDefinition(lons=lons_1d, lats=lats_1d)\n",
    "\n",
    "        # Longitudes latitudes to which we will we interpolate\n",
    "        lon_tmp = np.arange(-180, 180, dx) + dx/2\n",
    "        lat_tmp = np.arange(-90, 90, dy) + dy/2\n",
    "\n",
    "        # Define the lat lon points of the two parts.\n",
    "        self.new_grid_lon, self.new_grid_lat = np.meshgrid(lon_tmp, lat_tmp)\n",
    "        self.new_grid  = pyresample.geometry.GridDefinition(lons=self.new_grid_lon,\n",
    "                                                            lats=self.new_grid_lat)\n",
    "\n",
    "    def __call__(self, da, ax=None, lon_0=-60, tstr=None, **plt_kwargs):\n",
    "\n",
    "        assert set(da.dims) == set(['face', 'j', 'i']), \"da must have dimensions ['face', 'j', 'i']\"\n",
    "\n",
    "        field = pyresample.kd_tree.resample_nearest(self.orig_grid, da.values,\n",
    "                                                    self.new_grid,\n",
    "                                                    radius_of_influence=100000,\n",
    "                                                    fill_value=None)\n",
    "\n",
    "        x,y = self.new_grid_lon, self.new_grid_lat\n",
    "\n",
    "        p = ax.pcolormesh(x, y, field, transform=cart.crs.PlateCarree(), **plt_kwargs)\n",
    "        #p = ax.contourf(x, y, field, transform=cart.crs.PlateCarree(), **plt_kwargs)\n",
    "\n",
    "        #ax.coastlines()\n",
    "        # ax.add_feature(cart.feature.LAND, zorder=100, edgecolor='k')\n",
    "        #ax.add_feature(cart.feature.LAND, facecolor=landcolor, edgecolor='k',  zorder=3, linewidth=0.3)\n",
    "        gl = ax.gridlines(zorder=4)\n",
    "\n",
    "        if tstr is not None:\n",
    "            ax.set_title('%s'%(tstr))\n",
    "            \n",
    "        label = None\n",
    "        # if da.name is not None:\n",
    "        #     label = da.name\n",
    "        # if 'units' in da.attrs:\n",
    "        #     label += ' (%s)' % da.attrs['units']\n",
    "        # cbarextend='both'\n",
    "        # try:\n",
    "        #     mynorm = plt_kwargs.pop('norm')\n",
    "        #     if mynorm.vmin == 0.: cbarextend='max'\n",
    "        # except:\n",
    "        #     cbarextend='both'\n",
    "\n",
    "        # shrinkfac=1.\n",
    "        # cb = plt.colorbar(p, ax=ax, shrink=shrinkfac, label=label, extend=cbarextend, orientation='horizontal')\n",
    "\n",
    "        return ax, p, gl\n",
    "    \n",
    "class LLCinterp:\n",
    "\n",
    "    def __init__(self, ds, dx=0.25, dy=0.25):\n",
    "        # Extract LLC 2D coordinates\n",
    "        lons_1d = ds.XC.values.ravel()\n",
    "        lats_1d = ds.YC.values.ravel()\n",
    "\n",
    "        # Define original grid\n",
    "        self.orig_grid = pyresample.geometry.SwathDefinition(\n",
    "            lons=lons_1d, lats=lats_1d)\n",
    "\n",
    "        # Longitudes latitudes to which we will we interpolate\n",
    "        lon_tmp = np.arange(-180, 180, dx) + dx/2\n",
    "        lat_tmp = np.arange(-90, 90, dy) + dy/2\n",
    "\n",
    "        # Define the lat lon points of the two parts.\n",
    "        self.new_grid_lon, self.new_grid_lat = np.meshgrid(lon_tmp, lat_tmp)\n",
    "        self.new_grid  = pyresample.geometry.GridDefinition(\n",
    "            lons=self.new_grid_lon, lats=self.new_grid_lat)\n",
    "\n",
    "    def __call__(self, da):\n",
    "\n",
    "        assert set(da.dims) == set(\n",
    "            ['face', 'j', 'i']), \"da must have dimensions ['face', 'j', 'i']\"\n",
    "\n",
    "        field = pyresample.kd_tree.resample_nearest(self.orig_grid, da.values,\n",
    "                                                    self.new_grid,\n",
    "                                                    radius_of_influence=100e3,\n",
    "                                                    fill_value=None)\n",
    "        return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyresample\n",
    "\n",
    "class LLCMapper_wog:\n",
    "\n",
    "    def __init__(self, ds, dx=0.25, dy=0.25):\n",
    "        # Extract LLC 2D coordinates\n",
    "        lons_1d = ds.XC.values.ravel()\n",
    "        lats_1d = ds.YC.values.ravel()\n",
    "\n",
    "        # Define original grid\n",
    "        self.orig_grid = pyresample.geometry.SwathDefinition(lons=lons_1d, lats=lats_1d)\n",
    "\n",
    "        # Longitudes latitudes to which we will we interpolate\n",
    "        lon_tmp = np.arange(-180, 180, dx) + dx/2\n",
    "        lat_tmp = np.arange(-90, 90, dy) + dy/2\n",
    "\n",
    "        # Define the lat lon points of the two parts.\n",
    "        self.new_grid_lon, self.new_grid_lat = np.meshgrid(lon_tmp, lat_tmp)\n",
    "        self.new_grid  = pyresample.geometry.GridDefinition(lons=self.new_grid_lon,\n",
    "                                                            lats=self.new_grid_lat)\n",
    "\n",
    "    def __call__(self, da, ax=None, lon_0=-60, tstr=None, **plt_kwargs):\n",
    "\n",
    "        assert set(da.dims) == set(['face', 'j', 'i']), \"da must have dimensions ['face', 'j', 'i']\"\n",
    "\n",
    "        field = pyresample.kd_tree.resample_nearest(self.orig_grid, da.values,\n",
    "                                                    self.new_grid,\n",
    "                                                    radius_of_influence=100000,\n",
    "                                                    fill_value=None)\n",
    "\n",
    "        x,y = self.new_grid_lon, self.new_grid_lat\n",
    "\n",
    "        p = ax.pcolormesh(x, y, field, transform=cart.crs.PlateCarree(), **plt_kwargs)\n",
    "        #p = ax.contourf(x, y, field, transform=cart.crs.PlateCarree(), **plt_kwargs)\n",
    "\n",
    "        ax.coastlines()\n",
    "        # ax.add_feature(cart.feature.LAND, zorder=100, edgecolor='k')\n",
    "        ax.add_feature(cart.feature.LAND, facecolor=landcolor, edgecolor='k',  zorder=3, linewidth=0.3)\n",
    "#        gl = ax.gridlines(zorder=4)\n",
    "\n",
    "        if tstr is not None:\n",
    "            ax.set_title('%s'%(tstr))\n",
    "            \n",
    "        label = None\n",
    "        # if da.name is not None:\n",
    "        #     label = da.name\n",
    "        # if 'units' in da.attrs:\n",
    "        #     label += ' (%s)' % da.attrs['units']\n",
    "        # cbarextend='both'\n",
    "        # try:\n",
    "        #     mynorm = plt_kwargs.pop('norm')\n",
    "        #     if mynorm.vmin == 0.: cbarextend='max'\n",
    "        # except:\n",
    "        #     cbarextend='both'\n",
    "\n",
    "        # shrinkfac=1.\n",
    "        # cb = plt.colorbar(p, ax=ax, shrink=shrinkfac, label=label, extend=cbarextend, orientation='horizontal')\n",
    "\n",
    "        return ax, p, gl\n",
    "    \n",
    "class LLCinterp:\n",
    "\n",
    "    def __init__(self, ds, dx=0.25, dy=0.25):\n",
    "        # Extract LLC 2D coordinates\n",
    "        lons_1d = ds.XC.values.ravel()\n",
    "        lats_1d = ds.YC.values.ravel()\n",
    "\n",
    "        # Define original grid\n",
    "        self.orig_grid = pyresample.geometry.SwathDefinition(\n",
    "            lons=lons_1d, lats=lats_1d)\n",
    "\n",
    "        # Longitudes latitudes to which we will we interpolate\n",
    "        lon_tmp = np.arange(-180, 180, dx) + dx/2\n",
    "        lat_tmp = np.arange(-90, 90, dy) + dy/2\n",
    "\n",
    "        # Define the lat lon points of the two parts.\n",
    "        self.new_grid_lon, self.new_grid_lat = np.meshgrid(lon_tmp, lat_tmp)\n",
    "        self.new_grid  = pyresample.geometry.GridDefinition(\n",
    "            lons=self.new_grid_lon, lats=self.new_grid_lat)\n",
    "\n",
    "    def __call__(self, da):\n",
    "\n",
    "        assert set(da.dims) == set(\n",
    "            ['face', 'j', 'i']), \"da must have dimensions ['face', 'j', 'i']\"\n",
    "\n",
    "        field = pyresample.kd_tree.resample_nearest(self.orig_grid, da.values,\n",
    "                                                    self.new_grid,\n",
    "                                                    radius_of_influence=100e3,\n",
    "                                                    fill_value=None)\n",
    "        return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b2f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyresample\n",
    "\n",
    "class LLCMapper_2:\n",
    "\n",
    "    def __init__(self, ds, dx=0.25, dy=0.25):\n",
    "        # Extract LLC 2D coordinates\n",
    "        lons_1d = ds.XC.values.ravel()\n",
    "        lats_1d = ds.YC.values.ravel()\n",
    "\n",
    "        # Define original grid\n",
    "        self.orig_grid = pyresample.geometry.SwathDefinition(lons=lons_1d, lats=lats_1d)\n",
    "\n",
    "        # Longitudes latitudes to which we will we interpolate\n",
    "        lon_tmp = np.arange(-180, 180, dx) + dx/2\n",
    "        lat_tmp = np.arange(-90, 90, dy) + dy/2\n",
    "\n",
    "        # Define the lat lon points of the two parts.\n",
    "        self.new_grid_lon, self.new_grid_lat = np.meshgrid(lon_tmp, lat_tmp)\n",
    "        self.new_grid  = pyresample.geometry.GridDefinition(lons=self.new_grid_lon,\n",
    "                                                            lats=self.new_grid_lat)\n",
    "\n",
    "    def __call__(self, da, ax=None, lon_0=-60, tstr=None, **plt_kwargs):\n",
    "\n",
    "        assert set(da.dims) == set(['face', 'j', 'i']), \"da must have dimensions ['face', 'j', 'i']\"\n",
    "\n",
    "        field = pyresample.kd_tree.resample_nearest(self.orig_grid, da.values,\n",
    "                                                    self.new_grid,\n",
    "                                                    radius_of_influence=100000,\n",
    "                                                    fill_value=None)\n",
    "\n",
    "        x,y = self.new_grid_lon, self.new_grid_lat\n",
    "\n",
    "        #p = ax.pcolormesh(x, y, field, transform=cart.crs.PlateCarree(), **plt_kwargs)\n",
    "        p = ax.contourf(x, y, field, transform=cart.crs.PlateCarree(), **plt_kwargs)\n",
    "\n",
    "        ax.coastlines()\n",
    "        # ax.add_feature(cart.feature.LAND, zorder=100, edgecolor='k')\n",
    "        ax.add_feature(cart.feature.LAND, facecolor=landcolor, edgecolor='k',  zorder=3, linewidth=.3)\n",
    "        gl = ax.gridlines(zorder=4)\n",
    "\n",
    "        if tstr is not None:\n",
    "            ax.set_title('%s'%(tstr))\n",
    "            \n",
    "        label = None\n",
    "        # if da.name is not None:\n",
    "        #     label = da.name\n",
    "        # if 'units' in da.attrs:\n",
    "        #     label += ' (%s)' % da.attrs['units']\n",
    "        # cbarextend='both'\n",
    "        # try:\n",
    "        #     mynorm = plt_kwargs.pop('norm')\n",
    "        #     if mynorm.vmin == 0.: cbarextend='max'\n",
    "        # except:\n",
    "        #     cbarextend='both'\n",
    "\n",
    "        # shrinkfac=1.\n",
    "        # cb = plt.colorbar(p, ax=ax, shrink=shrinkfac, label=label, extend=cbarextend, orientation='horizontal')\n",
    "\n",
    "        return ax, p, gl\n",
    "    \n",
    "class LLCinterp:\n",
    "\n",
    "    def __init__(self, ds, dx=0.25, dy=0.25):\n",
    "        # Extract LLC 2D coordinates\n",
    "        lons_1d = ds.XC.values.ravel()\n",
    "        lats_1d = ds.YC.values.ravel()\n",
    "\n",
    "        # Define original grid\n",
    "        self.orig_grid = pyresample.geometry.SwathDefinition(\n",
    "            lons=lons_1d, lats=lats_1d)\n",
    "\n",
    "        # Longitudes latitudes to which we will we interpolate\n",
    "        lon_tmp = np.arange(-180, 180, dx) + dx/2\n",
    "        lat_tmp = np.arange(-90, 90, dy) + dy/2\n",
    "\n",
    "        # Define the lat lon points of the two parts.\n",
    "        self.new_grid_lon, self.new_grid_lat = np.meshgrid(lon_tmp, lat_tmp)\n",
    "        self.new_grid  = pyresample.geometry.GridDefinition(\n",
    "            lons=self.new_grid_lon, lats=self.new_grid_lat)\n",
    "\n",
    "    def __call__(self, da):\n",
    "\n",
    "        assert set(da.dims) == set(\n",
    "            ['face', 'j', 'i']), \"da must have dimensions ['face', 'j', 'i']\"\n",
    "\n",
    "        field = pyresample.kd_tree.resample_nearest(self.orig_grid, da.values,\n",
    "                                                    self.new_grid,\n",
    "                                                    radius_of_influence=100e3,\n",
    "                                                    fill_value=None)\n",
    "        return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad1ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyresample\n",
    "\n",
    "class LLCMapper_3:\n",
    "\n",
    "    def __init__(self, ds, dx=0.25, dy=0.25):\n",
    "        # Extract LLC 2D coordinates\n",
    "        lons_1d = ds.XC.values.ravel()\n",
    "        lats_1d = ds.YC.values.ravel()\n",
    "\n",
    "        # Define original grid\n",
    "        self.orig_grid = pyresample.geometry.SwathDefinition(lons=lons_1d, lats=lats_1d)\n",
    "\n",
    "        # Longitudes latitudes to which we will we interpolate\n",
    "        lon_tmp = np.arange(-180, 180, dx) + dx/2\n",
    "        lat_tmp = np.arange(-90, 90, dy) + dy/2\n",
    "\n",
    "        # Define the lat lon points of the two parts.\n",
    "        self.new_grid_lon, self.new_grid_lat = np.meshgrid(lon_tmp, lat_tmp)\n",
    "        self.new_grid  = pyresample.geometry.GridDefinition(lons=self.new_grid_lon,\n",
    "                                                            lats=self.new_grid_lat)\n",
    "\n",
    "    def __call__(self, da, ax=None, lon_0=-60, tstr=None, **plt_kwargs):\n",
    "\n",
    "        assert set(da.dims) == set(['face', 'j', 'i']), \"da must have dimensions ['face', 'j', 'i']\"\n",
    "\n",
    "        field = pyresample.kd_tree.resample_nearest(self.orig_grid, da.values,\n",
    "                                                    self.new_grid,\n",
    "                                                    radius_of_influence=100000,\n",
    "                                                    fill_value=None)\n",
    "\n",
    "        x,y = self.new_grid_lon, self.new_grid_lat\n",
    "\n",
    "        #p = ax.pcolormesh(x, y, field, transform=cart.crs.PlateCarree(), **plt_kwargs)\n",
    "        p = ax.contour(x, y, field, transform=cart.crs.PlateCarree(), **plt_kwargs)\n",
    "\n",
    "        ax.coastlines()\n",
    "        # ax.add_feature(cart.feature.LAND, zorder=100, edgecolor='k')\n",
    "        ax.add_feature(cart.feature.LAND, facecolor=landcolor, edgecolor='k',  zorder=3, linewidth=.3)\n",
    "        gl = ax.gridlines(zorder=4)\n",
    "\n",
    "        if tstr is not None:\n",
    "            ax.set_title('%s'%(tstr))\n",
    "            \n",
    "        label = None\n",
    "        # if da.name is not None:\n",
    "        #     label = da.name\n",
    "        # if 'units' in da.attrs:\n",
    "        #     label += ' (%s)' % da.attrs['units']\n",
    "        # cbarextend='both'\n",
    "        # try:\n",
    "        #     mynorm = plt_kwargs.pop('norm')\n",
    "        #     if mynorm.vmin == 0.: cbarextend='max'\n",
    "        # except:\n",
    "        #     cbarextend='both'\n",
    "\n",
    "        # shrinkfac=1.\n",
    "        # cb = plt.colorbar(p, ax=ax, shrink=shrinkfac, label=label, extend=cbarextend, orientation='horizontal')\n",
    "\n",
    "        return ax, p, gl\n",
    "    \n",
    "class LLCinterp:\n",
    "\n",
    "    def __init__(self, ds, dx=0.25, dy=0.25):\n",
    "        # Extract LLC 2D coordinates\n",
    "        lons_1d = ds.XC.values.ravel()\n",
    "        lats_1d = ds.YC.values.ravel()\n",
    "\n",
    "        # Define original grid\n",
    "        self.orig_grid = pyresample.geometry.SwathDefinition(\n",
    "            lons=lons_1d, lats=lats_1d)\n",
    "\n",
    "        # Longitudes latitudes to which we will we interpolate\n",
    "        lon_tmp = np.arange(-180, 180, dx) + dx/2\n",
    "        lat_tmp = np.arange(-90, 90, dy) + dy/2\n",
    "\n",
    "        # Define the lat lon points of the two parts.\n",
    "        self.new_grid_lon, self.new_grid_lat = np.meshgrid(lon_tmp, lat_tmp)\n",
    "        self.new_grid  = pyresample.geometry.GridDefinition(\n",
    "            lons=self.new_grid_lon, lats=self.new_grid_lat)\n",
    "\n",
    "    def __call__(self, da):\n",
    "\n",
    "        assert set(da.dims) == set(\n",
    "            ['face', 'j', 'i']), \"da must have dimensions ['face', 'j', 'i']\"\n",
    "\n",
    "        field = pyresample.kd_tree.resample_nearest(self.orig_grid, da.values,\n",
    "                                                    self.new_grid,\n",
    "                                                    radius_of_influence=100e3,\n",
    "                                                    fill_value=None)\n",
    "        return field"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mitgcm_2",
   "language": "python",
   "name": "mitgcm_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
